{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PGGANの論文：[201710]Progessive Growing of GANs for Improved Quality, Stability, and Variation\n",
    "- Tero Karras達, Nvidia\n",
    "- https://arxiv.org/abs/1710.10196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement the PGGAN using TFHubの理由\n",
    "- The original implementation of PGGAN took the NVIDIA researchers **one to two months to run**, which we thought was impractical for any person to run on their own, especially if you want to experiment or get something wrong.\n",
    "- PGGANの実現コードが膨大で、TFHub allows us to skip over the boilerplate code and focus on the ideas that matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Latent space interpolation\n",
    "- the initial trained latent space has **semantically meaningful** properties.\n",
    "- 応用例：We can pick two random vectors and then move in equal increments between them and so gradually - smoothly - get an image that matches the second vector.\n",
    "- Not only is the generative process predictable, but also the output is **not jagged - or reacting sharply to small changes** - considering the latent vector changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Progressive growing and smoothing of higher-resolution layers\n",
    "- progressive growing.\n",
    " - 低解像度（小さい層）からどんどん**zoom in** (increase the complexity).\n",
    "     - zoom inの実現は、adding extra layers.\n",
    "     - increases in complexity only as we gain confidence that we are at the approximately right part of the loss space.\n",
    "<img src=\"img/pggan-progressive-growing-2020-02-23 21-42-23.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- smoothly fade in.\n",
    " - fade inするのは低解像度の層。なぜなら、高解像度層をintroduceしたらメインは高解像度層をトレーニングするのだ。\n",
    " - なぜsmoothly fade in?\n",
    "     - upon introducing even one more layer at a time, we are still introducing a massive shock to the training.\n",
    "     - だからPGGANの発明者はsmoothly fade in trained lower resolution layers, in order to give the system **time to adapt to the higher resolution**.\n",
    " - やり方：高解像度層を導入後、一気に高解像度層通路に入れ替えるではなく、**２つ通路**の状態でトレーニングする。\n",
    "     - 通路１：高解像度通路、重みは$\\alpha$。\n",
    "     - 通路２：学習済み低解像度通路（upscaleだけ）、重みは$1-\\alpha$。パラメータなし。\n",
    "         - simple nearest neighbor upscaling, which does not have any trained parameters.\n",
    "     - 下記図(a)(b)(c)状態で全部自信が出るまでトレーニングする。\n",
    "<img src=\"img/pggan-smoothly-fade-in-2020-02-23 21-56-19.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 Mini-batch standard deviation\n",
    "- 課題対象：mode collapse.\n",
    " - 意味：the generator collapses which produces **limited varieties of samples**.例えばgeneratorが生成した数字の中に8が全然ない。\n",
    "- 対策：Discriminatorにmini-batch standard deviationに構成された１つfeature mapを追加。\n",
    "- Mini-batch standard deviationの計算や使用方法：\n",
    " - scalarの計算。例えばDiscriminatorの入力tensorが[B,W,H,C]のサイズ。\n",
    " - まずはB軸（axis=0, batch_size）に対してstandard deviationを計算。つまりstddevのサイズは[W,H,C]です。\n",
    " - またwidth, height, channelsに対して、stddevの平均値(scalar)を計算する。\n",
    " - 最後はこのmean stddev scalarを使って、[B,W,H]サイズのtensorを作って、layerに１つfeature mapとして追加する。\n",
    "- 小さいmini-batch standard deviationを罰する。\n",
    " - 小さいmini-batch standard deviationだったら、つまりgeneratorが生成した画像の多様性が足りない。\n",
    " - 多様性が足りないと、Discriminatorはこれらが偽物だろうと分かる。本当の画像たちだとvarianceが高いはず。\n",
    "- 本のコードが間違っているところが多いそう。下記のページの実装は分かりやすい。https://machinelearningmastery.com/how-to-train-a-progressive-growing-gan-in-keras-for-synthesizing-faces/\n",
    " - また、このページを見ると、MinibatchStddev層は入力画像が1つ目Conv2D, LeakyReLUのあとで1回のみ適用されている。\n",
    "<img src=\"img/pggan-minibatch-stddev-2020-02-24 00-38-04.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.5 Pixel-wise feature normalization in the generator\n",
    "- 超簡単。tensorのdepth軸で正規化する。\n",
    "- なぜbatch normalizationを使わない？\n",
    " - batch normalizationはbatch_size軸で正規化するので、batch_sizeが大きい方が効果が出る。\n",
    " - しかし高解像度の場合、メモリの制限が厳しくなるので、batch_sizeは大きくなれない。\n",
    " - だから有効な小さいbatch_size場合の正規化が必要です。\n",
    " - その対策は、[BatchSize,Width,Height,Depth] tensorのDepth軸で正規化すること。\n",
    "     - つまりpixelごとに正規化する。\n",
    "     - $n_{x,y}=a_{x,y}/\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1}(a_{x,y}^j)^2+\\epsilon}$.\n",
    "     - $N$はthe number of feature maps.\n",
    "- PixelNormalizationはGeneratorにのみ適用している。\n",
    " - The explosion in the activation magnitudes leads to an arms race **only if both** networks participate.\n",
    "<img src=\"img/pixel-wise-norm-2020-02-24 14-24-58.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1: Progressive Growing & Smoothing in of Higher Resolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今回のコードはテストなしなので、間違っているところが多いようで、流れが分かったらOK。\n",
    "def upscale_layer(layer, upscale_factor):\n",
    "    # layerのサイズは[batch, height, width, channels]と期待している。\n",
    "    height, width = layer.get_shape()[1:3]\n",
    "    # upscale_factor倍でサイズを拡大する。\n",
    "    size = (upscale_factor * height, upscale_factor * width)\n",
    "    upscaled_layer = tf.image.resize_nearest_neighbor(layer, size)\n",
    "    return upscale_layer\n",
    "\n",
    "def smoothly_merge_last_layer(list_of_layers, alpha):\n",
    "    # list_of_layers: tensors ordered by size。つまりlast layerは[-2]、最新層は[-1]。\n",
    "    last_fully_trained_layer = list_of_layers[-2]\n",
    "    # 学習済みの前の層を2倍拡大。\n",
    "    last_layer_upscaled = upscale_layer(last_fully_trained_layer, 2)\n",
    "    \n",
    "    larger_native_layer = list_of_layers[-1]\n",
    "    assert larger_native_layer.get_shape() == last_layer_upscaled.get_shape()\n",
    "    \n",
    "    new_layer = (1-alpha) * last_layer_upscaled + alpha * larger_native_layer\n",
    "    \n",
    "    return new_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 4: Pixel-wise Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **kwargsは任意keyworded（key=value）入力。\n",
    "def pixelwise_feat_norm(inputs, **kwargs):\n",
    "    # axis=-1はchannels軸だ。もしinputsのサイズが[B,H,W,C]だったら、normalization_constantのサイズは[B,H,W,1]になる。\n",
    "    normalization_constant = K.backend.sqrt(K.backend.mean(\n",
    "        inputs**2, axis=-1, keepdims=True) + 1.0e-8)\n",
    "    return inputs / normalization_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Running PGGAN from tensorflow Hub\n",
    "## tensorflow Hubのインストール\n",
    "- https://www.tensorflow.org/hub/installation\n",
    "- TensorFlow 2が進めされている。まずtensorflow2にアップグレードしましょう。現在のtensorflowバージョンは1.14。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c017171c13e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
